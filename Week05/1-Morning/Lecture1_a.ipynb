{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSS 201.5 - CSS Bootcamp\n",
    "\n",
    "## Week 05, Lecture 01: Probability, Statistics, and Inference\n",
    "\n",
    "### Umberto Mignozzetti (UCSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "### Week 01\n",
    "\n",
    "- Intro to data analysis\n",
    "- Basic Calculus\n",
    "\n",
    "### Week 02\n",
    "\n",
    "- Advanced data analysis\n",
    "- Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "### Week 03\n",
    "\n",
    "- Computing\n",
    "- Microteaching\n",
    "- How to date in Swedish (yes, I am sorry for you...)\n",
    "\n",
    "### Week 04\n",
    "\n",
    "- Probability Theory\n",
    "- Python Programming\n",
    "\n",
    "Great work! You are all awesome!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Do you have any questions about the last week's PS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\newcommand\\pN{N}$\n",
    "$\\newcommand\\pE{\\mathop{{}\\mathbb{E}}}$\n",
    "$\\newcommand\\pV{\\mathop{{}\\mathbb{V}}}$\n",
    "$\\newcommand\\pP{\\mathop{{}\\mathbb{P}}}$\n",
    "$\\newcommand{\\ind}{\\perp\\!\\!\\!\\!\\perp}$\n",
    "$\\newcommand{\\bX}{\\mathbf{X}}$\n",
    "\n",
    "\n",
    "## This week\n",
    "\n",
    "### Morning\n",
    "\n",
    "- Finish probability theory\n",
    "- Inference\n",
    "\n",
    "### Afternoon\n",
    "\n",
    "- Advanced programming\n",
    "\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\be}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bbs}{\\mathbf{b}}$\n",
    "$\\newcommand{\\bbeta}{\\mathbf{\\beta}}$\n",
    "$\\newcommand{\\hbbeta}{\\widehat{\\mathbf{\\beta}}}$\n",
    "$\\newcommand{\\bhb}{\\widehat{\\mathbf{b}}}$\n",
    "$\\newcommand{\\bvx}{\\mathbf{x}}$ \n",
    "$\\newcommand{\\Ex}{\\mathbb{E}}$\n",
    "$\\newcommand{\\Vax}{\\mathbb{V}}$\n",
    "$\\newcommand{\\real}{\\mathbb{R}}$\n",
    "$\\newcommand{\\realp}{\\mathbb{R}^{+}}$\n",
    "$\\newcommand{\\cov}{\\text{Cov}}$\n",
    "$\\newcommand{\\convp}{\\overset{p}{\\longrightarrow}}$\n",
    "$\\newcommand{\\convd}{\\overset{d}{\\longrightarrow}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability Theory\n",
    "\n",
    "So far, we did:\n",
    "\n",
    "1. Set theory applied to probability\n",
    "2. Elementary probability (probability measure and its properties)\n",
    "3. Counting methods (sampling, permutations, and combinations)\n",
    "4. Random variables\n",
    "5. Basics of probability distributions over random variables\n",
    "6. PDFs, CDFs, and their properties\n",
    "\n",
    "Learn this amount of content is freaking awesome! Are you a bunch of sponges or what?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Function\n",
    "\n",
    "### *Fair Bets*\n",
    "\n",
    "Suppose:\n",
    "\n",
    "1. That $X$ is the amount of rain that will fall tomorrow, and $X$ has c.d.f. $F$.\n",
    "\n",
    "2. That we want to place an even-money bet on $X$ as follows:\n",
    "    1. If $X \\leq x_0$, we win one dollar and if $X>x_0$ we lose one dollar. \n",
    "\n",
    "In order to make this bet fair, we need: $$P(X \\leq x_0) = P(X > x_0) = 1/2$$\n",
    "\n",
    "We could search through all of the real numbers $x$ trying to find one such that $F(x) = 1/2$, and then we would let $x_0$ equal the value we found. \n",
    "\n",
    "If $F$ is a one-to-one function, then $F$ has an inverse $F^−1$ and $x_0 = F^{−1}(1/2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Function\n",
    "\n",
    "### *Standardized Scores*\n",
    "\n",
    "Most universities are not interested in your scores, but in your placement in your cohort.\n",
    "\n",
    "This is true for SAT and GRE scores: the points do not matter. What matters really is the percentile they represent.\n",
    "\n",
    "Example: if $x$ points put you in the 90th percentile, it means that your achievement is better than 90\\% of the students.\n",
    "\n",
    "This is what we call *quantile*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Function\n",
    "\n",
    "### Quantiles/Percentiles\n",
    "\n",
    "- Let $X$ be a random variable with c.d.f. $F$.\n",
    "- For each $p$ strictly between $0$ and $1$, define $F^{−1}(p)$ to be the smallest value $x$ such that $F(x) \\geq p$.\n",
    "\n",
    "$F^{−1}(p)$ is called the $p$ **quantile** of $X$ or the $100p$ percentile of $X$. \n",
    "\n",
    "The function $F^{−1}$ defined here on the open interval $(0, 1)$ is called the quantile function of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Function\n",
    "\n",
    "### Example\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im4.png?raw=true)\n",
    "\n",
    "Let $X \\sim \\text{Uniform}([a,b])$. Find $F$ (the CDF) and $F^{-1}$ (the quantile function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Functions\n",
    "\n",
    "### Quantiles of Discrete Distributions\n",
    "\n",
    "Look at this CDF:\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im3.png?raw=true)\n",
    "\n",
    "When $p \\in [z_0, z_1]$, the smallest $x$ such that $F(x) \\geq p$ is $x_1$. \n",
    "\n",
    "Because distribution functions are continuous from the right, the smallest $x$ such that $F(x) \\geq p$\n",
    "exists for all $0<p<1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Functions\n",
    "\n",
    "### Quantiles of Discrete Distributions (Example)\n",
    "\n",
    "Let $X$ have the binomial distribution with parameters $n = 5$ and $p = 0.3$. \n",
    "\n",
    "The binomial table in the back of the book has the p.f. $f$ of $X$, which we reproduce here together with the CDF F:\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im5.png?raw=true)\n",
    "\n",
    "And the quantile function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Functions\n",
    "\n",
    "### Median and quantiles\n",
    "\n",
    "- The $1/2$ quantile or the 50-th percentile of a distribution is called its median.\n",
    "- The $1/4$ quantile or 25-th percentile is the lower quartile.\n",
    "- The $3/4$ quantile or 75-th percentile is called the upper quartile.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Suppose that $X$ has the PDF:\n",
    "\n",
    "$$f(x) =\n",
    "  \\begin{cases}\n",
    "    2x & \\text{for $0 \\leq x \\leq 1$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "1. Find and sketch the CDF or X.\n",
    "1. Find the (a) median; (b) 90-th percentile; (c) the quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantile Functions\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Find the quantile function for:\n",
    "\n",
    "$$F(x) =\n",
    "  \\begin{cases}\n",
    "    0 & \\text{for $x < 0$}, \\\\\n",
    "    x^{\\frac{2}{3}} & \\text{for $0 \\leq x \\leq 1$}, \\\\\n",
    "    1 & \\text{for $x > 1$}\n",
    "  \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "In science, we rarely deal with just one variable.\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. If you talk about income, I can ask about the relationship between income and education\n",
    "2. If you talk about vote, I can ask about the relationship between ideology and vote\n",
    "3. If you want to increase sales, I can ask about seasonality, or product reviews\n",
    "4. And so on...\n",
    "\n",
    "It is frequently the case that we are interested in multiple random variables.\n",
    "\n",
    "Let us understand how do they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "**Definition**: Let $X$ and $Y$ be random variables. The joint distribution of $X$ and $Y$ is the collection of all probabilities of the form $P[(X,Y) \\in C]$ for all sets $C$ of pairs of real numbers such that $\\{(X, Y) \\in C\\}$ is an event.\n",
    "\n",
    "This definition is somewhat abstract, but examples will clarify it.\n",
    "\n",
    "**Discrete Joint Distribution**: \n",
    "\n",
    "- Let $X$ and $Y$ be random variables, and consider the ordered pair $(X, Y)$. If there are only finitely or at most countably many different possible values $(x, y)$ for the pair $(X, Y)$, then we say that $X$ and $Y$ have a discrete joint distribution.\n",
    "\n",
    "**Joint Probability Function (discrete)**: \n",
    "\n",
    "- The joint probability function of $X$ and\n",
    "$Y$ is defined as the function $f$ such that for every point $(x, y)$ in the xy-plane:\n",
    "\n",
    "$$f(x, y) = P(X = x \\text{ and } Y = y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "Example: What is the joint distribution of the clinical trial results below\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im13.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "**Properties**: Let X and Y have a discrete joint distribution. \n",
    "\n",
    "1. If $(x, y)$ is ***not*** one of the possible values of the pair $(X, Y)$, then $f(x, y) = 0$.\n",
    "\n",
    "1. $\\sum_{\\text{All } (x,y)} f(x,y) = 1$\n",
    "\n",
    "1. $P[(X,Y) \\in C] = \\sum_{(x,y) \\in C}f(x,y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Let a suburban area where $X$ stand for the number of cars owned by a household and $Y$ the number of television sets owned by that same household. \n",
    "\n",
    "The joint PF of X and Y is:\n",
    "\n",
    "![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im7.png?raw=true)\n",
    "\n",
    "1. What is the chance that a household has one car?\n",
    "2. What is the chance that a household has more than one TV set?\n",
    "3. What is the chance that a household with two cars has more than three TV sets?\n",
    "4. Do the numbers sum up to one? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Example\n",
    "\n",
    "And this is the graph of the PDF:\n",
    "\n",
    "![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im8.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Continuous Joint Distribution/Joint PDF/Support\n",
    "\n",
    "Two random variables $X$ and $Y$ have a continuous joint distribution if there exists a nonnegative function $f$ defined over the entire xy-plane such that for every subset C of the plane,\n",
    "\n",
    "$$P[(X, Y) \\in C] = \\int_C\\int f(x, y)dxdy$$\n",
    "\n",
    "The function $f$ is called the ***joint probability density function*** (abbreviated joint PDF) of $X$ and $Y$. \n",
    "\n",
    "The closure of the set $\\{(x,y): \\ f(x, y) > 0\\}$ is called the ***support*** of (the distribution of) $(X, Y)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "#### Example: Continuous Joint Distribution\n",
    "\n",
    "![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im9.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Example: calculating a normalizing constant\n",
    "\n",
    "Suppose that the joint PDF of $X$ and $Y$ is:\n",
    "\n",
    "$$f(x) =\n",
    "  \\begin{cases}\n",
    "    cx^2y & \\text{for $x^2 \\leq y \\leq 1$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "What is the value of $c$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "Using the $c$ above, what is $P(X \\geq Y)$? (spoiler: 3/20)\n",
    "\n",
    "$$f(x) =\n",
    "  \\begin{cases}\n",
    "    cx^2y & \\text{for $x^2 \\leq y \\leq 1$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Slice 1 | Slice 2\n",
    "- | - \n",
    "![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im10.png?raw=true) | ![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im11.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Consider a public utility planning for the summer models the demand for water $X$ and electricity $Y$ as:\n",
    "\n",
    "$$f(x, y) =\n",
    "  \\begin{cases}\n",
    "    \\dfrac{1}{29204} & \\text{for $4 \\leq x \\leq 200$ and $1 \\leq y \\leq 150$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "What is the chance that the water demand $X$ is greater than electric demand $Y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Mixed Bivariate Distributions\n",
    "\n",
    "Let $X$ and $Y$ be random variables such that $X$ is discrete and $Y$ is continuous.\n",
    "\n",
    "Suppose that there is a function $f(x, y)$ defined on the xy-plane such that, for every pair $A$ and $B$ of subsets of the real numbers,\n",
    "\n",
    "$$P(X \\in A \\text{ and } Y \\in B) = \\int_B\\sum_{x \\in A}f(x,y)dy$$\n",
    "\n",
    "Then the function $f$ is called the joint PF/PDF of $X$ and $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Mixed Bivariate Distributions (example)\n",
    "\n",
    "Prove that $f$ is a joint PDF of $X$ and $Y$:\n",
    "\n",
    "$$f(x, y) =\n",
    "  \\begin{cases}\n",
    "    \\dfrac{xy^{x-1}}{3} & \\text{for $x = 1, 2, 3$ and $0 < y < 1$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Exercise\n",
    "\n",
    "What is the probability that $Y \\geq 1/2$ and $X \\geq 2$? (spoiler: 0.5417)\n",
    "\n",
    "$$f(x, y) =\n",
    "  \\begin{cases}\n",
    "    \\dfrac{xy^{x-1}}{3} & \\text{for $x = 1, 2, 3$ and $0 < y < 1$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Joint CDF\n",
    "\n",
    "The joint distribution function or joint cumulative distribution function of two random variables $X$ and $Y$ is defined as $F$ such that for all values of $x$ and $y$ ($-\\infty<x<\\infty$ and $-\\infty<y<\\infty$):\n",
    "\n",
    "$$F(x, y) = P(X \\leq x \\text{ and } Y \\leq y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Joint CDF (Exercise)\n",
    "\n",
    "Suppose you know $F(x,y)$. Assuming $a < b$ and $c < d$, compute:\n",
    "\n",
    "$$P(a < X \\leq b \\text{ and } c < Y \\leq d)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "### Joint CDF's (important fact)\n",
    "\n",
    "$$f(x,y) = \\dfrac{\\partial^2F(x,y)}{\\partial x \\partial y}$$\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Compute $f(x,y)$ when\n",
    "\n",
    "$$F(x, y) =\n",
    "  \\begin{cases}\n",
    "    \\dfrac{xy(x+y)}{16} & \\text{for $0 \\leq x \\leq 2$ and $0 \\leq y \\leq 2$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Marginal Distributions\n",
    "\n",
    "Suppose that $X$ and $Y$ have a joint distribution. The CDF of $X$ is called the marginal CDF of $X$. \n",
    "\n",
    "Similarly, the PDF of $X$ associated with the marginal CDF of $X$ is called the marginal PDF of $X$. \n",
    "\n",
    "### Discrete Marginal CDF\n",
    "\n",
    "If $X$ and $Y$ have a discrete joint distribution for which the joint PDF is $f$, then the marginal PDF $f_1$ of $X$ is:\n",
    "\n",
    "$$f_1(x) = \\sum_{\\text{All }y}f(x, y)$$\n",
    "\n",
    "$f_2(y)$ is defined analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Marginal Distributions\n",
    "\n",
    "### Continuous Marginal CDF/PDF\n",
    "\n",
    "If $X$ and $Y$ have a continuous joint distribution with joint PDF $f$, then the marginal PDF $f_1$ of $X$ is:\n",
    "\n",
    "$$f_1(x) = \\int_{-\\infty}^{\\infty}f(x,y)dy$$\n",
    "\n",
    "$f_2(y)$ is defined analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bivariate Distributions\n",
    "\n",
    "**Check-in**: \n",
    "\n",
    "Suppose that in an electric display sign there are three light bulbs in the first row and four light bulbs in the second row. \n",
    "\n",
    "Let $X$ denote the number of bulbs in the first row that will be burned out at a specified time $t$, and let $Y$ denote the number of bulbs in the second row that will be burned out at the same time $t$. \n",
    "\n",
    "Suppose that the joint p.f. of $X$ and $Y$ is as specified in the following table:\n",
    "\n",
    "![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im12.png?raw=true)\n",
    "\n",
    "Compute:\n",
    "\n",
    "1. $P(X = 2)$\n",
    "1. $P(Y \\geq 2)$\n",
    "1. $P(X \\leq 2 \\text{ and } Y \\leq 2)$\n",
    "1. $P(X = Y)$\n",
    "1. $P(X > Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independent Random Variables\n",
    "\n",
    "Two random variables X and Y are independent if, for every two sets $A$ and $B$ of real numbers such that $\\{X \\in A\\}$ and $\\{Y \\in B\\}$ are events,\n",
    "\n",
    "$$P(X \\in A \\text{ and } Y \\in B) = P(X \\in A) P(Y \\in B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independent Random Variables\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose that the joint p.d.f. of $X$ and $Y$ is as follows:\n",
    "\n",
    "$$f(x, y) =\n",
    "  \\begin{cases}\n",
    "    \\dfrac{15}{4}x^2 & \\text{for $0 \\leq y \\leq 1-x^2$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "1. Determine the marginal PDFs of $X$ and $Y$.\n",
    "1. Are $X$ and $Y$ independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Marginal Distributions\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Suppose that $X$ and $Y$ have a continuous joint distribution for which the joint PDF is\n",
    "\n",
    "$$f(x, y) =\n",
    "  \\begin{cases}\n",
    "    k & \\text{for $a \\leq x \\leq b$ and $c \\leq y \\leq d$}, \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Find the marginal distributions of $X$ and $Y$. Are $X$ and $Y$ independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Distributions\n",
    "\n",
    "Let $X$ and $Y$ have a discrete joint distribution with joint PDF $f$. Let $f_2$ denote the marginal p.f. of $Y$. For each $y$ such that $f_2(y) > 0$, define:\n",
    "\n",
    "$$g_1(x|y) = \\dfrac{f(x, y)}{f2(y)}$$\n",
    "\n",
    "Then $g_1$ is called the **conditional PDF of X given Y**. \n",
    "\n",
    "The discrete distribution whose PDF is $g_1(.|y)$ is called the **conditional distribution of X given that $Y = y$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Distributions\n",
    "\n",
    "![alt](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im20.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independence\n",
    "\n",
    "### Implications of Independence\n",
    "\n",
    "Let $X$ and $Y$ two random variables with joint PDF $f$. The following statements are equivalent:\n",
    "\n",
    "1. $X \\perp Y$\n",
    "2. $\\forall x,y \\in \\mathbb{R}$, $f(x, y) = f_{X}(x)f_{Y}(y)$\n",
    "3. $\\forall x \\in \\mathbb{R}$ and $y \\in \\text{Supp}[Y]$, $f_{X|Y}(x|y) = f_{X}(x)$\n",
    "4. $\\forall D, E \\subseteq \\mathbb{R}$, the events $\\{X \\in D\\}$ and $\\{Y \\in E\\}$ are independent.\n",
    "5. For all functions $g$ of $X$ and $h$ of $Y$ $g(X) \\perp h(Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multivariate Generalizations\n",
    "\n",
    "- (Definition) **Random Vectors**: A random vector is a function $X: S \\rightarrow \\mathbb{R}^{K}$ such that, for all event A, $\\bX(A) \\ = \\ \\bigg( X_{1}(A), \\cdots, X_{K}(A) \\bigg)$. And where $X_{i}$ is a random variable.\n",
    "\n",
    "- (Definition) **Joint Cumulative Density Function**: For a random vector $\\bX$, evaluated at $\\bvx$, is denoted $F(\\bvx) = \\mathbb{P}\\left[ \\bX \\leq \\bvx \\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multivariate Generalizations\n",
    "\n",
    "And from here, the extensions are evident:\n",
    "\n",
    "- For continuous random vectors, we use multiple integrals (*CDF*s) or partial derivatives (*PDF*s)\n",
    "\n",
    "- For discrete random vectors, we use multiple sums (*CDF*s).\n",
    "\n",
    "- For the conditional *PDFs/PMFs*, we marginalize on the variables by summing up across their support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Theorem) **Expectation of a Function**: For a random variable $X$ with *PMF/PDF* $f$ and a function $g$ (still assuming bounded variation):\n",
    "  1. If $X$ is discrete, then $\\Ex [g(X)] \\ = \\ \\sum_{x}g(x)f(x)$\n",
    "  + If $X$ is continuous, then $\\Ex [g(X)] \\ = \\ \\int_{-\\infty}^{\\infty}g(x)f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Theorem) **Linearity of Expected Values**: For a random variable $X$, and $a, b \\in \\mathbb{R}$, then:\n",
    "\n",
    "$$\\Ex[aX + b] \\ = \\ a\\Ex[X] + b$$\n",
    "\n",
    "- (Definition) **Expectation of a Bivariate Random Vector**: For a random vector $(X,Y)$, the expected value is $\\Ex [(X, Y)] \\ = \\ \\bigg(\\Ex[X], \\Ex[Y] \\bigg)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Definition) **Raw Moment**: For a random variable $X$, the $j$-th *raw moment* is defined as:\n",
    "\n",
    "$$ \\mu_{j}' = \\Ex [X^{j}] $$\n",
    "\n",
    "- (Definition) **Central Moment**: For a random variable $X$, the $j$-th *central moment* is defined as:\n",
    "\n",
    "$$ \\mu_{j} = \\Ex \\left[(X -\\Ex [X])^{j} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Definition) **Variance**: For a random variable $X$, the variance is defined as the *second central moment* of $X$:\n",
    "\n",
    "$$ \\Vax [X] = \\Ex \\left[(X -\\Ex [X])^{2} \\right] $$\n",
    "\n",
    "- (Definition) **Standard Deviation**: For a random variable $X$, the variance is defined as $\\sigma [X] = \\sqrt{\\Vax[X]}$\n",
    "\n",
    "- (Theorem) **Alternative formula for the Variance**: For a random variable $X$, the variance is defined as the *second central moment* of $X$:\n",
    "\n",
    "$$ \\Vax [X] = \\Ex [X^2] - \\left[ \\Ex [X] \\right]^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Theorem) **Algebra of the Variance**: For a random variable $X$ and $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}$:\n",
    "\n",
    "$$ \\Vax [aX + b] \\ = \\ a^{2} \\Vax [X] $$\n",
    "\n",
    "- (Corollary) **Algebra of the Standard Deviations**: Let a random variable $X$, $a \\in \\mathbb{R}$, and $b \\in \\mathbb{R}$. Then, $\\sigma [aX + b] = |a| \\sigma [X]$.\n",
    "\n",
    "- (Theorem) **Chebyshev Inequality**: Let a random variable $X$ and $\\sigma [X] > 0$. Then, $\\forall \\epsilon > 0$:\n",
    "\n",
    "$$ \\mathbb{P} \\bigg[ \\big| X - \\Ex[X] \\big| \\geq \\epsilon \\sigma [X] \\bigg] \\leq \\dfrac{1}{\\epsilon^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Definition) **Normal Distribution**: A continuous random variable $X$ follows a normal distribution (denoted by $X \\sim N(\\mu, \\sigma^2)$) if:\n",
    "\n",
    "$$ f(x) \\ = \\ \\dfrac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\dfrac{(x - \\mu)^{2}}{2\\sigma^2}} $$\n",
    "\n",
    "- (Theorem) **Mean and Standard Deviation of a Normal Distribution**: Let $X \\sim N(\\mu, \\sigma^2)$. Then, $\\Ex[X] \\ = \\ \\mu$ and $\\sigma[X] \\ = \\ \\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Theorems) **Algebra of Normal Distributions**: Let $X \\sim N(\\mu_{X}, \\sigma_{X}^2)$, $Y \\sim N(\\mu_{Y}, \\sigma_{Y}^2)$, and $a, b \\in \\mathbb{R}$, $a \\neq 0$. Then:\n",
    "  1. If $W = aX + b$, then $W \\sim N(a\\mu_{X} + b, a^2\\sigma_{X}^2)$\n",
    "  2. If $X \\ind Y$, and $Z = X + Y$, then $Z \\sim N(\\mu_{X} + \\mu_{Y}, \\sigma_{X}^2 + \\sigma_{Y}^2)$\n",
    "\n",
    "- This proof should be straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- And one of the most important objects: suppose we want to say how well a random variable $X$ approximates a given value $c \\in \\mathbb{R}$.\n",
    "\n",
    "- The most common metric we use for this purpose is the *Mean Squared Error*.\n",
    "\n",
    "- (Definition) **Mean Squared Error**: The *MSE* of a random variable $X$ about $c$ is equal to: $\\Ex[(X - c)^2]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions\n",
    "\n",
    "- (Theorem) **Alternative formulation for the Mean Squared Error**: The *MSE* of a random variable about $c$ is equal to:\n",
    "\n",
    "$$ \\Ex[(X - c)^2] \\ = \\ \\Vax[X] + (\\Ex[X] - c)^2 $$\n",
    "\n",
    "- (Theorem) **Mean Squared Error Minimization**: The value $c$ that minimizes the *MSE* of a random variable $X$ about $c$ is $c = \\Ex[X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions (Joint Distributions)\n",
    "\n",
    "- (Definition) **Covariance**: The covariance of two random variables is defined as \n",
    "$$\\text{Cov}[X, Y] = \\big[ \\big(X - \\Ex[X]\\big)\\big(Y - \\Ex[Y]\\big) \\big] = \\Ex[XY] - \\Ex[X]\\Ex[Y]$$\n",
    "\n",
    "- (Theorem) **Variance Rule**: Let $X$ and $Y$ two r.v. Then,\n",
    "\n",
    "1. $$\\Vax[X + Y] = \\Vax[X] +2\\text{Cov}[X, Y] + \\Vax[Y]$$\n",
    "\n",
    "2. And if $a, b, c \\in \\real$, then $$\\Vax[aX + bY + c] = a^2\\Vax[X] +2ab\\text{Cov}[X, Y] + b^2\\Vax[Y]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions (Joint Distributions)\n",
    "\n",
    "- (Theorem) **Algebra of Covariance**: Let $X$, $Y$, $Z$, $W$ four r.v.s and $a,b,c,d \\in \\real$. Then:\n",
    "\n",
    "1. $\\text{Cov}[X, c]=\\text{Cov}[c, X]=\\text{Cov}[d, c]$\n",
    "2. $\\text{Cov}[X, Y] = \\text{Cov}[Y, X]$\n",
    "3. $\\text{Cov}[X, X] = \\Vax[X]$\n",
    "4. \n",
    "$$\\text{Cov}[X + W, Y + Z]=\\text{Cov}[X, Z]+\\text{Cov}[X, Y]+\\text{Cov}[W, Y]+\\text{Cov}[W,Z]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions (Joint Distributions)\n",
    "\n",
    "(Definition) **Correlation**: The correlation of two random variables $X$ and $Y$, with $\\sigma[X]>0$ and $\\sigma[Y]>0$ is defined as \n",
    "$$\\rho[X, Y] = \\dfrac{\\cov[X,Y]}{\\sigma[X]\\sigma[Y]}$$\n",
    "\n",
    "(Theorem) **Correlation and Linear Dependence**: Let two random variables $X$ and $Y$, with $\\sigma[X]>0$ and $\\sigma[Y]>0$. Then:\n",
    "\n",
    "1. $\\rho[X, Y] \\in [-1, 1]$\n",
    "\n",
    "2. For $a, b \\in \\real$, and $Y = aX + b$:\n",
    "    - $\\rho[X, Y] = 1$ if $a > 0$\n",
    "    - $\\rho[X, Y] = -1$ if $a < 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing Distributions (Joint Distributions)\n",
    "\n",
    "(Theorem) **Properties of Correlation**: Let random variables $X$, $Y$, and $Z$, all with variance higher than zero. Let also $a,b,c,d \\in \\real$.\n",
    "1. $\\rho[X, Y] = \\rho[Y, X]$\n",
    "2. $\\rho[X, X] = 1$\n",
    "3. If $ab>0$, then $\\rho[aX + c, bY + d] = \\rho[X,Y]$\n",
    "4. If $ab<0$, then $\\rho[aX + c, bY + d] = -\\rho[X,Y]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independence\n",
    "\n",
    "(Theorem) **Independence**: Let $X$ and $Y$ two independents r.v.s. Then:\n",
    "1. $\\rho[X, Y] = 0$\n",
    "2. $\\cov[X, Y] = 0$\n",
    "3. $\\Ex[XY] = \\Ex[X]\\Ex[Y]$\n",
    "4. $\\Vax[X + Y] = \\Vax[X] + \\Vax[Y]$\n",
    "\n",
    "- However, these statements are not equivalent, since you may have $\\rho[X, Y] = 0$ without having independence!\n",
    "  + See pages 65 and 66 of the Aronow and Miller book (especially the footnote on pg 66 for a notable exception)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "(Definition) **Conditional Expectation**: For two random variables $X$ and $Y$, the conditional expectation of $Y$ given $X=x$ is:\n",
    "\n",
    "1. If $X$ and $Y$ are discrete, and $x \\in \\text{Supp}[X]$, then $$\\Ex[Y|X=x] = \\sum_{y}yf_{Y|X}(y|x)$$\n",
    "\n",
    "2. If $X$ and $Y$ are continuous, and $x \\in \\text{Supp}[X]$, then $$\\Ex[Y|X=x] = \\int_{-\\infty}^{\\infty}yf_{Y|X}(y|x)dy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "(Definition) **Conditional Expectation of a function**: For two random variables $X$ and $Y$ and a function of $X$ and $Y$, the conditional expectation of $h(X,Y)$ given $X=x$ is:\n",
    "\n",
    "1. If $X$ and $Y$ are discrete, and $x \\in \\text{Supp}[X]$, then $$\\Ex[h(X,Y)|X=x] = \\sum_{y}h(x,y)f_{Y|X}(y|x)$$\n",
    "\n",
    "2. If $X$ and $Y$ are continuous, and $x \\in \\text{Supp}[X]$, then $$\\Ex[h(X,Y)|X=x] = \\int_{-\\infty}^{\\infty}h(x,y)f_{Y|X}(y|x)dy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "(Theorem) **Linearity of Conditional Expectation**: Let $X$ and $Y$ rvs. If $g$ and $h$ are functions (with $x \\in \\text{Supp}[X]$ is: \n",
    "\n",
    "$$\\Ex[g(X)Y + h(X) | X=x] = g(x)\\Ex[Y | X=x] + h(x)$$\n",
    "\n",
    "(Definition) **Conditional Expectation Function**: Let $X$ and $Y$ rvs with joint distribution $f$ ($x \\in \\text{Supp}[X]$) is: \n",
    "\n",
    "$$G_Y(x) = \\Ex[Y | X=x]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "(Theorem) **Law of Iterated Expectations**: Let $X$ and $Y$ rvs. \n",
    "\n",
    "$$\\Ex[Y] = \\Ex\\big[\\Ex[Y | X]\\big]$$\n",
    "\n",
    "(Theorem) **Law of Total Variance**: Let $X$ and $Y$ rvs. \n",
    "\n",
    "$$\\Vax[Y] = \\Ex\\big[\\Vax[Y | X]\\big] + \\Vax\\big[\\Ex[Y | X]\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "(Theorem) **Properties of Deviations from the CEF**: Let $X$ and $Y$ rvs and let $\\epsilon = Y - \\Ex[Y|X]$.\n",
    "\n",
    "1. $\\Ex[\\epsilon|X] = 0$\n",
    "2. $\\Ex[\\epsilon] = 0$\n",
    "3. If $g$ is a function of $X$, $\\cov\\big[g(X),\\epsilon \\big] = 0$\n",
    "4. $\\Vax[\\epsilon|X] = \\Vax[Y|X]$\n",
    "5. $\\Vax[\\epsilon] = \\Ex\\big[\\Vax[Y|X]\\big]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "- (Theorem) **Properties of Deviations from the CEF**: Let $X$ and $Y$ rvs and let $\\epsilon = Y - \\Ex[Y|X]$.\n",
    "\n",
    "1. $\\Ex[\\epsilon|X] = 0$\n",
    "2. $\\Ex[\\epsilon] = 0$\n",
    "3. If $g$ is a function of $X$, $\\cov\\big[g(X),\\epsilon \\big] = 0$\n",
    "4. $\\Vax[\\epsilon|X] = \\Vax[Y|X]$\n",
    "5. $\\Vax[\\epsilon] = \\Ex\\big[\\Vax[Y|X]\\big]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Function\n",
    "\n",
    "(Theorem) **CEF and Best Linear Predictor**: Let $X$ and $Y$ rvs, $\\Ex[Y|X]$ is the best predictor of $Y$ given $X$.\n",
    "\n",
    "(Theorem) **Best Linear Predictor**: Let $X$ and $Y$ rvs, if $\\Vax[X] > 0$, then the BLP of $Y$ given $X$ is $g(X) = \\beta_0 + \\beta_1X$ where:\n",
    "\n",
    "1. $\\beta_0 = \\Ex[Y] - \\beta_1\\Ex[X]$\n",
    "\n",
    "2. $\\beta_1 = \\dfrac{\\cov[X,Y]}{\\Vax[X]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Function\n",
    "\n",
    "(Theorem) **Implications of Independence**: Let $X$ and $Y$ independent rvs.:\n",
    "\n",
    "1. $\\Ex[Y|X] = \\Ex[Y]$\n",
    "2. $\\Vax[Y|X] = \\Vax[Y]$\n",
    "3. The BLP of $Y$ given $X$ is $\\Ex[Y]$\n",
    "4. If $g$ is a function of $X$ and $h$ is a function of $Y$:\n",
    "    - $\\Ex[h(Y)|g(X)] = \\Ex[h(Y)]$\n",
    "    - The BLP of $h(Y)$ given $g(X)$ is $\\Ex[h(X)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectations\n",
    "\n",
    "**Definition -- Expected Value**: For a random variable $X$ with bounded variation:\n",
    "\n",
    "- If $X$ is discrete, then $E[X] \\ = \\ \\sum_{x}xf(x)$\n",
    "\n",
    "- If $X$ is continuous, then $E[X] \\ = \\ \\int_{-\\infty}^{\\infty}xf(x)$\n",
    " \n",
    "**Theorem -- Linearity of Expected Values**: For a random variable $X$, and $a, b \\in \\mathbb{R}$, then:\n",
    "\n",
    "$$E[aX + b] \\ = \\ aE[X] + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectations\n",
    "\n",
    "Example:\n",
    "\n",
    "A product has one year warranty. Let $X$ be the time at which the product fails. Suppose $X$ has the distribution\n",
    "\n",
    "$$\n",
    "f(x) =\n",
    "  \\begin{cases}\n",
    "    0 & \\text{for $x<1$}, \\\\\n",
    "    \\dfrac{2}{x^3} & \\text{for $x \\geq 1$}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "When is the expected time to failure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectations\n",
    "\n",
    "*What is an Expectation?* \n",
    "\n",
    "It is the center of gravity of a distribution. If we place the distribution in a plate, and put our fingers exactly in the mean, we would be able to balance it.\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im0.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectations\n",
    "\n",
    "**Theorem -- Expectation of the sum of Random Variables**: If $X_1, \\cdots, X_n$ are $n$ random variables such that each expectation $E(X_i)$ is finite ($i = 1, \\cdots, n$), then \n",
    "\n",
    "$$E(X_1 + \\cdots + X_n) = E(X_1) + \\cdots + E(X_n)$$\n",
    "\n",
    "**Theorem -- Expectation of the product of Random Variables**: If $X_1, \\cdots, X_n$ are $n$ independent random variables such that each expectation $E(X_i)$ is finite ($i = 1, \\cdots, n$), then \n",
    "\n",
    "$$E\\bigg(\\prod_{i=1}^ nX_i\\bigg) = \\prod_{i=1}^ nE(X_i)$$\n",
    "\n",
    "Example: Suppose that $X_1$, $X_2$, and $X_3$ are independent random variables such that $E(X_i) = 0$ and $E(X^2_i) = 1$ for $i = 1, 2, 3$. What is $E[X^2_1(X_2 - 4X_3)^2]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectations\n",
    "\n",
    "**Check-in**: A filtration process removes a random proportion of particulates in water to which it is applied. Suppose that a sample of water is subjected to this process twice. Let $X_1$ be the proportion of the particulates that are removed by the first pass. Let $X_2$ be the proportion of what remains after the first pass that is removed by the second pass. Assume that $X_1$ and $X_2$ are independent random variables with common p.d.f. $f(x) = 4x^3$ for $0 < x <1$ and $f(x) = 0$, otherwise. What proportion of particutes remain in the sample after two passes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variance\n",
    "\n",
    "Although the mean of a distribution is useful, it does not convey much information.\n",
    "\n",
    "- Two very different r.v.s can have the same mean without having much in common.\n",
    "\n",
    "But we can fix that by measuring the spread of a variable: the *variance*.\n",
    "\n",
    "**Definition -- Variance**: For a random variable $X$, the variance is defined as:\n",
    "\n",
    "$$ Var [X] = \\Ex \\left[(X -\\Ex [X])^{2} \\right] $$\n",
    "\n",
    "And the **standard deviation** of a variable $X$ is defined as $\\sigma_X = \\sqrt{Var[X]}$\n",
    "\n",
    "**Alternative formula for the Variance**:\n",
    "\n",
    "$$ Var [X] = \\Ex [X^2] - \\left[ \\Ex [X] \\right]^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variance\n",
    "\n",
    "**Properties:**\n",
    "\n",
    "1. For a random variable $X$ and constants $a$ and $b$, $Var [aX + b] \\ = \\ a^{2}Var[X]$ (and $\\sigma_{aX+b} = |a|\\sqrt{Var[X]}$)\n",
    "\n",
    "1. If $X_1, \\cdots , X_n$ are independent random variables with finite means, then $Var(X_1 + \\cdots + X_n) = Var(X_1) + \\cdots + Var(X_n)$\n",
    "\n",
    "**Check-in**: Suppose that one word is selected at random from the sentence THE GIRL PUT ON HER BEAUTIFUL RED HAT. If $X$ denotes the number of letters in the word that is selected, what is the value of Var(X)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moments\n",
    "\n",
    "- **Definition -- Raw Moment**: For a random variable $X$, the $j$-th *raw moment* is defined as:\n",
    "\n",
    "$$ \\mu_{j}' = E [X^{j}] $$\n",
    "\n",
    "- **Definition -- Central Moment**: For a random variable $X$, the $j$-th *central moment* is defined as:\n",
    "\n",
    "$$ \\mu_{j} = E \\left[(X -E [X])^{j} \\right] $$\n",
    "\n",
    "Things to remember:\n",
    "\n",
    "1. First central moment is always zero.\n",
    "1. Second central moment: *variance*\n",
    "1. Third central moment: *skewness*\n",
    "1. Very easy to compute moments if you take derivatives on $t$ using the moment generating function: $ \\psi(t) = E(e^{tX})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Median\n",
    "\n",
    "**Definition -- Median:** Let $X$ be a random variable. Every number $m$ with the following property is called a median of the distribution of $X$:\n",
    "\n",
    "$$P(X \\leq m) \\geq 1/2 \\text{  and  } P(X \\geq m) \\geq 1/2$$\n",
    "\n",
    "Things to remember:\n",
    "\n",
    "1. Median is the point (or points, there can be multiple medians) in the distribution divide the probability in 1/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Median\n",
    "\n",
    "Interesting: \n",
    "\n",
    "Suppose that the mean annual income among the families in a certain community is `$30,000`. \n",
    "\n",
    "It is possible that only a few families in the community actually have an income as large as `$30,000`, but those few families have incomes that are very much larger than `$30,000`. \n",
    "\n",
    "As an extreme example, suppose that there are 100 families and 99 of them have income of `$1,000` while the other one has income of `$2,901,000`. \n",
    "\n",
    "If, however, the median annual income among the families is `$30,000`, then at least one-half of the families must have incomes of `$30,000` or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean Squared Error\n",
    "\n",
    "Suppose a random variable with mean $\\mu$ and variance $\\sigma^2$. And suppose we want to predict the values of $X$ by selecting a number $d$.\n",
    "\n",
    "**Definition -- Mean Squared Error:** The number $E[(X-d)^ 2]$ is called *mean squared error* of the prediction $d$.\n",
    "\n",
    "If we want good predictions, we want to minimize the MSE. What number minimizes it?\n",
    "\n",
    "**Theorem -- Alternative formulation for the Mean Squared Error**: The *MSE* of a random variable about $c$ is equal to:\n",
    "\n",
    "$$ E[(X - c)^2] \\ = \\ Var[X] + (E[X] - c)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean Absolute Error\n",
    "\n",
    "Suppose a random variable with mean $\\mu$, median $m$, and variance $\\sigma^2$. And suppose we want to predict the values of $X$ by selecting a number $d$.\n",
    "\n",
    "**Definition -- Mean Absolute Error:** The number $E[|X-d|]$ is called *mean absolute error* of the prediction $d$.\n",
    "\n",
    "If we want good predictions, we want to minimize the MAE. What number minimizes it?\n",
    "\n",
    "Hint: Try proving $E(|X − m|) \\leq E(|X − d|)$ for all $d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MAE and MSE\n",
    "\n",
    "**Check-in** \n",
    "\n",
    "1. In a small community consisting of 153 families, the number of families that have $k$ children ($k = 0, 1, 2, \\cdots$) is given in the following table:\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im1.png?raw=true)\n",
    "\n",
    "Determine the mean and the median of the number of children per family. (For the mean, assume that all families with four or more children have only four children. Why doesn’t this point matter for the median?)\n",
    "\n",
    "1. If n houses are located at various points along a straight road, at what point along the road should a store be located in order to minimize the sum of the distances from the n houses to the store?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "For a single variable, these measures are great. We have spread and we have two measures of centrality.\n",
    "\n",
    "But we rarely deal with just one variable. In that matter, how much one random variable depends on the other?\n",
    "\n",
    "We need some definitions to be able to tackle that:\n",
    "\n",
    "**Definition -- Covariance:** Let $X$ and $Y$ be random  variables having finite means. Let $E(X) = \\mu_X$ and $E(Y) = \\mu_Y$. The covariance of $X$ and $Y$, which is denoted by $Cov(X, Y)$, is defined as\n",
    "\n",
    "$$Cov(X, Y) = E[(X − \\mu_X)(Y − \\mu_Y)]$$\n",
    "\n",
    "Or $Cov(X, Y) = E[XY] - E[X]E[Y]$ (provided that variances are finite)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "**Algebra of Covariance**: Let $X$, $Y$, $Z$, $W$ four r.v.s and $a,b,c,d \\in \\real$. \n",
    "\n",
    "Then:\n",
    "\n",
    "1. $\\text{Cov}[X, c]=\\text{Cov}[c, X]=\\text{Cov}[d, c]$\n",
    "\n",
    "2. $\\text{Cov}[X, Y] = \\text{Cov}[Y, X]$\n",
    "\n",
    "3. $\\text{Cov}[X, X] = Var[X]$\n",
    "\n",
    "4. $\\text{Cov}[X + W, Y + Z] = \\text{Cov}[X, Z] + \\text{Cov}[X, Y] + \\text{Cov}[W, Y]+\\text{Cov}[W,Z]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "Example: What is the covariance of $X$ and $Y$ when $f$ is:\n",
    "\n",
    "$$\n",
    "f(x, y) =\n",
    "  \\begin{cases}\n",
    "    2xy + 0.5 & \\text{for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$}, \\\\\n",
    "    0 & \\text{otherwise.}\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "Covariance is great, but it is affected by the magnitude of the random variables.\n",
    "\n",
    "Suppose we want a measure that is not affected by the magnitude of the r.v.s. This variable is going to be great when comparing two different sets of r.v.s\n",
    "\n",
    "**Definition -- Correlation:** Let $X$ and $Y$ be random variables with finite variances $\\sigma^2_X$ and $\\sigma^2_Y$, respectively. Then the correlation of $X$ and $Y$, which is denoted by $\\rho(X, Y)$, is defined as follows:\n",
    "\n",
    "$$\\rho(X, Y) = \\dfrac{Cov(X, Y)}{\\sigma_X\\sigma_Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "Example:\n",
    "\n",
    "What is the correlation of $X$ and $Y$ when $f$ is:\n",
    "\n",
    "$$\n",
    "f(x, y) =\n",
    "  \\begin{cases}\n",
    "    2xy + 0.5 & \\text{for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$}, \\\\\n",
    "    0 & \\text{otherwise.}\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "Important: Assuming we have random variables $U$, $V$, $X$, and $Y$ with the first two having mean zero, and all four having finite variance:\n",
    "\n",
    "1. Schwarz Inequality: U, V, rvs, then $[E(UV)]^2 \\leq  E(U^2)E(V^2)$\n",
    "\n",
    "1. Cauchy-Schwarz Inequality: X, Y, rvs, then $[Cov(X,Y)]^2 \\leq \\sigma_X^2\\sigma_Y^2$ and $-1 \\leq \\rho(X,Y) \\leq 1$\n",
    "\n",
    "1. $\\rho(X,Y)>0$: positively correlated; $\\rho(X,Y)>0$: negatively correlated; $\\rho(X,Y)=0$: uncorrelated\n",
    "\n",
    "1. $\\rho(X,Y)= \\rho(X,Y)$\n",
    "\n",
    "1. $\\rho(X,Y) = 1$\n",
    "\n",
    "1. If $ab>0$, then $\\rho(aX + c, bY + d) = \\rho(X,Y)$\n",
    "\n",
    "1. If $ab<0$, then $\\rho(aX + c, bY + d) = -\\rho(X,Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "Important:\n",
    "\n",
    "1. $Cov(X, Y) = \\rho(X, Y) = 0$\n",
    "\n",
    "1. $Var(aX + bY + c) = a^2Var(X) + b^2Var(Y) + 2abCov(X,Y)$\n",
    "\n",
    "1. If $X_1, \\cdots, X_n$ uncorrelated, then $$Var\\bigg(\\sum_{i=1}^ nX_i\\bigg) = \\sum_{i=1}^ nVar(X_i)$$\n",
    "\n",
    "**Theorem -- Independence**: Let $X$ and $Y$ two independents r.v.s. Then:\n",
    "\n",
    "1. $\\rho(X, Y) = 0$\n",
    "1. $Cov(X, Y) = 0$\n",
    "1. $E[XY] = E[X]E[Y]$\n",
    "1. $Var[X + Y] = Var[X] + Var[Y]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Covariance and Correlation\n",
    "\n",
    "**Two variables can be dependent but uncorrelated**: Suppose that the random variable $X$ can take only the three values −1, 0, and 1, and that each of these three values has the same probability. Also, let the random variable $Y$ be defined by the relation $Y = X^2$.\n",
    "\n",
    "- Dependence: The value of Y is determined by the value of $X$.\n",
    "- Correlation: Compute $Cov(X,Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation\n",
    "\n",
    "Another interesting way of summarize multiple distributions is to use conditional expectations.\n",
    "\n",
    "**Definition -- Conditional Expectation/Mean**. Let $X$ and $Y$ be random variables such that the mean of $Y$ exists and is finite. The conditional expectation (or conditional mean) of $Y$ given $X = x$ is denoted by $E(Y|x)$ and is defined to be the expectation of the conditional distribution of $Y$ given $X = x$.\n",
    "\n",
    "If $Y$ has a continuous conditional distribution given $X = x$ with conditional p.d.f. $g_2(y|x)$, then\n",
    "\n",
    "$$E(Y|x) = \\int_{-\\infty}^{\\infty}yg_2(y|x)dy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation\n",
    "\n",
    "Example:\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im2.png?raw=true)\n",
    "\n",
    "And the conditional expectation:\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation\n",
    "\n",
    "**Theorem -- Law of Iterated Expectations** (In the book, *Law of Total Probability for Expectations*): Let $X$ and $Y$ rvs. \n",
    "\n",
    "$$E[Y] = E\\big[E[Y | X]\\big]$$\n",
    "\n",
    "**Definition -- Conditional Variance:** For every given value $x$, let $Var(Y|x)$ denote:\n",
    "\n",
    "$$Var(Y|x) = E\\{ ([Y - E[Y|x])^2 | x \\}$$\n",
    "\n",
    "**Theorem -- Law of Total Variance**: Let $X$ and $Y$ rvs. \n",
    "\n",
    "$$Var[Y] = E\\big[Var[Y | X]\\big] + Var\\big[E[Y | X]\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction\n",
    "\n",
    "**Theorem:** (A bit hard to prove) The prediction $d(X)$ that minimizes $E\\{[Y − d(X)]^2\\}$ is $d(X) = E(Y|X)$.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose that 20 percent of the students who took a certain test were from school A and that the arithmetic average of their scores on the test was 80. Suppose also that 30 percent of the students were from school B and that the arithmetic average of their scores was 76. Suppose, finally, that the other 50 percent of the students were from school C and that the arithmetic average of their scores was 84. If a student is selected at random from the entire group that took the test, what is the expected value of her score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normal Distribution\n",
    "\n",
    "**Definition -- Normal Distribution**: A continuous random variable $X$ follows a normal distribution (denoted by $X \\sim N(\\mu, \\sigma^2)$) if:\n",
    "\n",
    "$$ f(x) \\ = \\ \\dfrac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\dfrac{(x - \\mu)^{2}}{2\\sigma^2}} $$\n",
    "\n",
    "**Theorem -- Mean and Standard Deviation of a Normal Distribution**: Let $X \\sim N(\\mu, \\sigma^2)$. Then, $E[X] \\ = \\ \\mu$ and $Var[X] \\ = \\ \\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.normal(loc = 0,     # Mean\n",
    "                     scale = 1,   # Standard Deviation\n",
    "                     size = 1000) # Number cooked\n",
    "sns.histplot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normal Distribution\n",
    "\n",
    "**Algebra of Normal Distributions**: \n",
    "\n",
    "Let $X \\sim N(\\mu_{X}, \\sigma_{X}^2)$, $Y \\sim N(\\mu_{Y}, \\sigma_{Y}^2)$, and $a, b \\in \\mathbb{R}$, $a \\neq 0$. Then:\n",
    "\n",
    "1. If $W = aX + b$, then $W \\sim N(a\\mu_{X} + b, a^2\\sigma_{X}^2)$\n",
    "2. If $X \\ind Y$, and $Z = X + Y$, then $Z \\sim N(\\mu_{X} + \\mu_{Y}, \\sigma_{X}^2 + \\sigma_{Y}^2)$\n",
    "\n",
    "**MGF**:\n",
    "\n",
    "$$\\psi(t) = e^{\\mu t + \\dfrac{1}{2}\\sigma^2t^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normal Distribution\n",
    "\n",
    "Important: Standard Normal Distribution: $\\mu = 0$ and $\\sigma = 1$. Properties:\n",
    "\n",
    "1. p.d.f: $\\phi(x) = \\dfrac{1}{(2\\pi)^{1/2}}e^{-\\dfrac{1}{2}x^2}$\n",
    "\n",
    "1. c.d.f.: $\\Phi(x) = \\int_{-\\infty}^x \\phi(x)dx$\n",
    "\n",
    "1. Symmetric: $\\Phi(-x) = 1 - \\Phi(x)$\n",
    "\n",
    "1. Transformation: $F(x) = \\Phi\\bigg(\\dfrac{x-\\mu}{\\sigma}\\bigg)$\n",
    "\n",
    "1. Quantiles: $F^{-1}(p) = \\mu + \\sigma \\Phi^{-1}(x)$\n",
    "\n",
    "![img](https://github.com/umbertomig/CSSBootCamp/blob/main/img/im4.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normal Distribution\n",
    "\n",
    "**Check-in**:\n",
    "\n",
    "If the temperature in degrees Fahrenheit at a certain location is normally distributed with a mean of 68 degrees and a standard deviation of 4 degrees, what is the distribution of the temperature in degrees Celsius at the same location? Find the 0.25 and 0.75 quantiles of the Fahrenheit temperature at the location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Functions\n",
    "\n",
    "**Theorem -- Properties of Deviations from the CEF**: Let $X$ and $Y$ rvs and let $\\epsilon = Y - E[Y|X]$.\n",
    "\n",
    "1. $E[\\epsilon|X] = 0$\n",
    "2. $E[\\epsilon] = 0$\n",
    "3. If $g$ is a function of $X$, $Cov\\big[g(X),\\epsilon \\big] = 0$\n",
    "4. $Var[\\epsilon|X] = Var[Y|X]$\n",
    "5. $Var[\\epsilon] = E\\big[Var[Y|X]\\big]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Function\n",
    "\n",
    "**Theorem -- CEF and Best Linear Predictor**: Let $X$ and $Y$ rvs, $E[Y|X]$ is the best predictor of $Y$ given $X$.\n",
    "\n",
    "**Theorem -- Best Linear Predictor**: Let $X$ and $Y$ r.v.s, if $Var[X] > 0$, then the BLP of $Y$ given $X$ is $g(X) = \\beta_0 + \\beta_1X$ where:\n",
    "\n",
    "1. $\\beta_0 = E[Y] - \\beta_1E[X]$\n",
    "\n",
    "2. $\\beta_1 = \\dfrac{Cov[X,Y]}{Var[X]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation Function\n",
    "\n",
    "**Theorem -- Implications of Independence**: Let $X$ and $Y$ independent rvs.:\n",
    "\n",
    "1. $E[Y|X] = E[Y]$\n",
    "2. $E[Y|X] = E[Y]$\n",
    "3. The BLP of $Y$ given $X$ is $E[Y]$\n",
    "4. If $g$ is a function of $X$ and $h$ is a function of $Y$:\n",
    "    - $E[h(Y)|g(X)] = E[h(Y)]$\n",
    "    - The BLP of $h(Y)$ given $g(X)$ is $E[h(X)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Great work!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
